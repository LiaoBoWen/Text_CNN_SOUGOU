# Text_CNN_SOUGOU

*简介
主要利用CNN卷积神经网络和新闻文本的短文本（新闻摘要）进行文本分类。主要步骤如下
1.利用搜狗新闻语料库数据作为模型训练数据。一共有15个类别。处理为不同的类别进行存储为txt文件。类别字典存储在data/data_process文件夹下！new_class.txt
2.对取出的新闻文本数据，文本清洗，去停用词、加载新词、分词的顺序进行预处。处理为分好词的数据并且为文本都贴上标签，保存为新的文件descriptions.csv。
3.加载训练数据，取3000条数据为验证集，剩下的数据为训练集。利用CNN卷积神经网络模型进行训练，在训练的过程中保存好模型。
4.利用事先准备好的测试集数据，test_data.csv文件对训练好的模型进行性能评估。
5.对于通过性能评估的模型，进行实际使用，加载训练好的模型和待分类文本数据，进行分类，支持单个文本文件以及包含多个文本内容的文本文件进行分类（csv文件）。
并且将分类结果保存到prediction.csv文件中。

开发环境Python-v3(3.6)：
pymysql ==
jieba==0.39
scikit-learn==0.19.1
pandas==0.20.0
numpy==1.14.5+mkl
scipy==0.19.0
tensorflow == 1.80


1、数据和文本处理(data_process)包含三个文件
①data_catch.py为获取训练数据和测试数据test_data.csv,村联数据这里对搜狗新闻语料库数据做初步处理提取出标签和文本，并且按照类别进行存储。
存放在data/content文件夹中，test_data.csv测试文件直接存放在data文件夹中。
②data_process_train.py主要是针对训练数据进行预处理工作，文本处理包括文本清洗、去停用词处理、中文分词、去掉出现次数少的分词。保存为train_texts.csv文件。
并且提供函数将干净的训练数据对应 处理为分词后的文本和相应的标签数据，并且生成batch数据集。
文本处理包括文本清洗、去停用词处理、中文分词、去掉出现次数少的分词
③data_process_eval.py主要是用于测试集数据的处理以及实际使用的数据读入处理。
④在prediction模块中的predictionapp.py文件提供了从数据库取出数据，并且将分类结果返回给数据库的接口。

2、模型训练（model_train）
①cnn_model.py文件主要是用于定义一个CNN_TEXT类，一个用于模型训练的卷神经网络结构。结构包括词嵌入层、卷积池化层，全连接层以及输出层。
②cnn_train.py文件主要用作模型训练，包括定义相关的参数，模型的保存，以及summaries的保存。模型训练准确率达到95%以上。训练好的模型保存在
model_train文件下的runs文件夹中

3、模型测试（model_eval）
①model_test.py 文件主要用于模型测试工作，对test.csv文件进行测试，返回测试的准确率。
②model_app.py 文件是实际应用的文件，对模型进行实际使用，读入待分类数据，加载模型，进行分类，并将分类结果保存为prediction.csv文件中存贮。

4、模型应用（prediction）

*用法
1、先单独运行data_catch.py文件，得到训练数据，训练数据将会保存到新建的data/contens文件夹中。测试数据也会一并下载。
2、运行data_process_train.py文件，对训练数据进行预处理，并将处理好的数据保存为train_texts.csv文件。
3、然后运行cnn_train.py文件，开始训练模型，训练的模型，词表以及summaries豆浆保存在model_train文件夹下面的runs文件夹中。
4、运行model_test.py文件，对模型进行测试。也可以运行model_eval.py文件导入自己的数据，进行测试。提供多种导入方式。
5、运行prediction模块中的model_app文件可以应用模型，可以自动从数据库中得到数据，然后加载模型进行分类，并且将分类结果返回给
数据库，可以知己在原表插入结果，也可以重新建立一张新表存储分类结果。可进行选择，自定义每次取出多少条数据。
5、定义好需要分类的文本文件目录，运行文件，进行分类，并且自动保存分类结果。
